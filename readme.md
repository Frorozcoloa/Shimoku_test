# Informe  de entrenamiento

# Ingenier铆a de caracter铆sticas

## datasets offers.csv

En el proceso inicial del entrenamiento del modelo, se llev贸 a cabo la ingenier铆a de caracter铆sticas como primer paso. Para esto, se realizaron tres an谩lisis exploratorios con el objetivo de comprender las caracter铆sticas del negocio. En primer lugar, se examin贸 el conjunto de datos, realizando un an谩lisis detallado de cada columna y su posible relaci贸n con la variable predictora.

### Status

El enfoque inicial consisti贸 en analizar la variable objetivo, donde se procedi贸 a examinar todas las clases disponibles. Como resultado de este an谩lisis, se tom贸 la decisi贸n de mantener las clases "Closed Won" y "Closed Loss". Esta elecci贸n se bas贸 en la capacidad de estas clases para describir de manera precisa el objetivo del modelo, que es proporcionar un puntaje que var铆a entre 0 y 1. En este contexto, el valor 0 representa la probabilidad de perder un cierre, mientras que el valor 1 indica la probabilidad de lograr un cierre exitoso. Este enfoque busca optimizar la capacidad del modelo para realizar un scoring efectivo en la clasificaci贸n de oportunidades de negocio.

**Title: Distribuci贸n de la variable status**

![1702156015245](image/readme/1702156015245.png)

Tras realizar este proceso, se observ贸 que el 57.9% de las instancias pertenec铆an a la clase "Closed Won" y el 42.1% a la clase "Closed Loss". Este equilibrio en la distribuci贸n de clases indic贸 que no exist铆a un desbalanceo significativo en los datos. Con esta consideraci贸n, se procedi贸 a eliminar los datos relacionados con la otra clase, consolidando as铆 un conjunto de datos m谩s enfocado y representativo para el objetivo del modelo.

### Use Case

La segunda variable analizada fue "use_case". Este an谩lisis proporcion贸 una comprensi贸n m谩s profunda del caso de uso de la plataforma. Los resultados indicaron una fuerte asociaci贸n con eventos corporativos. En consecuencia, se tom贸 la decisi贸n de crear una variable binaria para clasificar los casos como eventos corporativos y eventos no corporativos. Esta nueva variable binaria se introdujo con el objetivo de capturar y reflejar de manera m谩s efectiva la naturaleza espec铆fica de los eventos corporativos en relaci贸n con el rendimiento del modelo.

**Title: Distribuci贸n de la variable use case**

![1702156529270](image/readme/1702156529270.png)

La evaluaci贸n de la variable "use_case" revel贸 que no exist铆a un desbalanceo significativo, y se destac贸 su predominante aplicaci贸n en eventos corporativos.

### Precio

Posteriormente, la atenci贸n se centr贸 en la variable de "precio". Durante el an谩lisis, se identificaron varios valores iguales a cero, sugiriendo que algunos clientes hab铆an obtenido servicios de manera gratuita. Aunque la distribuci贸n de esta variable mostraba un sesgo hacia la izquierda, se determin贸 que no ten铆a un impacto sustancial en la m茅trica de AUC, la cual se explicar谩 m谩s adelante por qu茅 fue seleccionada como m茅trica principal. Se realizaron pruebas con correcciones utilizando logaritmos y normalizaci贸n, sin embargo, se observ贸 que estas modificaciones no generaban cambios significativos en la m茅trica AUC.

**Title: Distribuci贸n de la variable precio**

![1702157284450](image/readme/1702157284450.png)

**Title: Distribuci贸n de la variable np.log(precio+1)**

![1702157341465](image/readme/1702157341465.png)

Se procedi贸 con un an谩lisis de las distribuciones de datos, tanto en su forma cruda como despu茅s de las transformaciones realizadas. Este an谩lisis permiti贸 visualizar la efectividad de las transformaciones aplicadas y su impacto en la estructura de los datos.

### Loss Reason

Adem谩s, se llev贸 a cabo un exhaustivo an谩lisis exploratorio de la nulidad de los datos. En particular, se examin贸 la variable "loss_reason", y se identific贸 una correlaci贸n de 1 mediante la correlaci贸n de Cram茅r con la variable "status". Esta alta correlaci贸n, respaldada por la naturaleza y los valores de la variable, sugiri贸 que "loss_reason" era un registro de las razones por las cuales un cliente no adquiri贸 el producto. Se realiz贸 un experimento entrenando modelos con esta variable, y se observ贸 que los modelos generaban m茅tricas del AUC cercanas a 0.99. Este hallazgo indic贸 la presencia de una fuga de datos (data leak) y, en consecuencia, se tom贸 la decisi贸n de eliminar la variable "loss_reason" del conjunto de datos.

Esta acci贸n se bas贸 en la necesidad de mantener la integridad del modelo y evitar la introducci贸n de informaci贸n sesgada o filtrada que pudiera afectar la generalizaci贸n del modelo en entornos del mundo real.

**Title: Heatmap de la matrix de correlaci贸n de variables categ贸ricas**

![1702157903119](image/readme/1702157903119.png)

Adicionalmente, se explor贸 la correlaci贸n de la variable "loss_reason" no solo con "status" sino tambi茅n con las variables "precio" y "discount_code". La correlaci贸n identificada con estas variables refuerza la evidencia de que "loss_reason" ten铆a informaci贸n cr铆tica para la predicci贸n del modelo y, por lo tanto, su eliminaci贸n fue justificada.

### Discount code

En el caso de "discount_code", se observ贸 que, aunque el c贸digo en s铆 mismo no aportaba informaci贸n 煤til, la presencia de valores nulos indicaba que el cliente no hab铆a recibido un c贸digo de descuento. Este hallazgo result贸 significativo, ya que se revel贸 que la existencia de un c贸digo de descuento era una variable crucial para el modelo. Como consecuencia, se transform贸 la variable "discount_code" en una variable binaria que indicaba la presencia o ausencia de un c贸digo de descuento, facilitando as铆 la interpretaci贸n y aplicaci贸n efectiva en el modelo.

Esta transformaci贸n permiti贸 mantener la informaci贸n esencial relacionada con los descuentos sin comprometer la calidad del modelo, al tiempo que se simplificaba la representaci贸n de la variable para una mejor compatibilidad con el proceso de entrenamiento.

**Title: Distribuci贸n de la variable has Discount code**

![1702158224356](image/readme/1702158224356.png)

### Open date y closed date

La siguiente fase del an谩lisis se centr贸 en las variables "open_date" y "closed_date". A partir de estas, se deriv贸 una variable adicional de gran relevancia: la duraci贸n. La duraci贸n se define como la diferencia en d铆as entre la fecha de cierre y la fecha de apertura de la oportunidad de negocio. Durante este proceso, se identificaron valores negativos, interpretados como el tiempo de duraci贸n de la oferta. Se consider贸 que estos datos podr铆an deberse a errores de digitaci贸n, dado que no se contaba con informaci贸n sobre la forma de adquisici贸n de los datos.

Aunque en una etapa inicial no se tiene informaci贸n sobre el tiempo real de negociaci贸n, la creaci贸n de la variable de duraci贸n permitir谩 realizar an谩lisis posteriores para comprender si los clientes requieren tiempo adicional para entender el producto o adquirir m谩s informaci贸n. Este an谩lisis tambi茅n podr铆a ayudar a determinar si es posible llevar a cabo una negociaci贸n de manera inmediata. En esencia, se trata de alinear el horario del equipo comercial con las necesidades y comportamientos de los clientes.

Es importante destacar que se entrenaron los modelos tanto con la variable de duraci贸n como sin ella. La eliminaci贸n de esta variable result贸 en una disminuci贸n significativa, del orden del 10%, en las m茅tricas del modelo, resaltando as铆 su relevancia en la predicci贸n del rendimiento de las oportunidades de negocio.

La siguiente fase del an谩lisis se centr贸 en las variables "open_date" y "closed_date". A partir de estas, se deriv贸 una variable adicional de gran relevancia: la duraci贸n. La duraci贸n se define como la diferencia en d铆as entre la fecha de cierre y la fecha de apertura de la oportunidad de negocio. Durante este proceso, se identificaron valores negativos, interpretados como el tiempo de duraci贸n de la oferta. Se consider贸 que estos datos podr铆an deberse a errores de digitaci贸n, dado que no se contaba con informaci贸n sobre la forma de adquisici贸n de los datos.

Aunque en una etapa inicial no se tiene informaci贸n sobre el tiempo real de negociaci贸n, la creaci贸n de la variable de duraci贸n permitir谩 realizar an谩lisis posteriores para comprender si los clientes requieren tiempo adicional para entender el producto o adquirir m谩s informaci贸n. Este an谩lisis tambi茅n podr铆a ayudar a determinar si es posible llevar a cabo una negociaci贸n de manera inmediata. En esencia, se trata de alinear el horario del equipo comercial con las necesidades y comportamientos de los clientes.

Es importante destacar que se entrenaron los modelos tanto con la variable de duraci贸n como sin ella. La eliminaci贸n de esta variable result贸 en una disminuci贸n significativa, del orden del 10%, en las m茅tricas del modelo, resaltando as铆 su relevancia en la predicci贸n del rendimiento de las oportunidades de negocio.

**Title: Distribuci贸n de la variable duraci贸n**![1702159214077](image/readme/1702159214077.png)

Al explorar la distribuci贸n de la variable de duraci贸n, se observ贸 que la m茅trica se ubicaba alrededor de 0, con valores comprendidos principalmente entre -500 y 500. Esta caracter铆stica refuerza la hip贸tesis de que los valores negativos podr铆an deberse a errores de digitaci贸n o a una interpretaci贸n inadecuada de los datos. La presencia de valores centrados en torno a 0 indica que, en su mayor铆a, las oportunidades de negocio ten铆an una duraci贸n relativamente corta o nula, lo cual puede ser atribuible a la inmediatez en las transacciones o a la falta de informaci贸n adicional.

A pesar de la incertidumbre inicial sobre la autenticidad de estos valores, el an谩lisis posterior demostr贸 que la variable de duraci贸n desempe帽aba un papel crucial en la mejora de las m茅tricas del modelo. Esta informaci贸n respalda la decisi贸n de retener la variable, incluso con la presencia de valores at铆picos, ya que contribuye significativamente a la capacidad predictiva del modelo en cuanto al cierre exitoso de oportunidades de negocio.

**Title: AUC de dataset de testeo sin la variable duraci贸n**

![1702159377873](image/readme/1702159377873.png)

Podemos ver que el AUC sin est谩 varaiable baja a un 0.82% cuando teniendo est谩 variable se  llega a un 0.92%

**Title: AUC de dataset de testeo con la variable duraci贸n**

![1702159784627](image/readme/1702159784627.png)

### Pain

La variable "Pain" sigui贸 un proceso similar en t茅rminos de transformaci贸n. Se decidi贸 convertirla en una variable booleana para simplificar su representaci贸n. En esta nueva formulaci贸n, se asign贸 el valor "True" a las instancias que involucraban operaciones relacionadas con "Pain", mientras que cualquier otro valor se etiquet贸 como "False".

**Title: Distribuci贸n de la variable Pain**

![1702161401477](image/readme/1702161401477.png)

## Dataset lead

Para los datos externos, se procedi贸 a fusionar los conjuntos de datos "lead.csv" y "offers", creando as铆 un dataset m谩s compacto. Este nuevo conjunto de datos fue sometido a un an谩lisis detallado de cada variable, destacando tres de especial importancia: ciudad, Acquisition Campaign, Source y Created Date. Dado el tama帽o reducido del conjunto de datos, se evalu贸 la relevancia de agregar estas variables como caracter铆sticas, considerando que su contribuci贸n podr铆a ser insignificante en comparaci贸n con otras variables.

Para abordar este desaf铆o, se asign贸 a cada variable informaci贸n sobre su nulidad, especificando si la oferta proven铆a de una campa帽a de adquisici贸n, si estaba asociada a una ciudad o si ten铆a un objetivo claro. Respecto a "Created Date", se llev贸 a cabo una transformaci贸n restando su valor al de "open_date". Esta operaci贸n gener贸 una nueva variable que indicaba el tiempo transcurrido desde que un cliente potencial se convirti贸 en cliente objetivo, o si el valor era negativo, desde que se le realiz贸 la oferta hasta que se volvi贸 cliente potencial.

Esta estrategia permiti贸 maximizar la utilidad de los datos externos, incorporando informaci贸n valiosa de manera efectiva en el modelo de entrenamiento. La interpretaci贸n de estas variables complementarias se ajust贸 para adaptarse al contexto de la predicci贸n de cierres exitosos de oportunidades de negocio.

Entre las variables externas analizadas, se identific贸 que la m谩s relevante para el modelo era la que indicaba si la oferta proven铆a de un evento corporativo.

**title: Heatmap de correlaci贸n de variables categ贸ricas del la uni贸n de los dos datasets**

![1702162630705](image/readme/1702162630705.png)

Recordemos que se cre贸 un dataset m谩s peque帽o.

**title: Importancia de variables para el modelo.**

![1702162186691](image/readme/1702162186691.png)

podemos identifica la variable was_corporate_event como la 5 de mayor importancia para el modelo.

## Conclusi贸n

En conclusi贸n, el an谩lisis detallado del primer conjunto de datos revel贸 que la informaci贸n 煤nica contenida en este conjunto fue fundamental para la identificaci贸n de las variables m谩s importantes para el modelo. La ingenier铆a de caracter铆sticas realizada en este conjunto permiti贸 destacar aspectos cruciales, como la presencia de c贸digos de descuento, la duraci贸n de las oportunidades de negocio, y la distinci贸n entre ofertas asociadas a eventos corporativos y otras fuentes.

Aunque se incorporaron datos externos para enriquecer la informaci贸n, fue el conjunto de datos original el que proporcion贸 las variables m谩s influyentes para la predicci贸n del modelo. Este descubrimiento subraya la importancia de realizar un an谩lisis minucioso de los datos disponibles y resalta c贸mo la comprensi贸n profunda de las caracter铆sticas espec铆ficas de los clientes y las oportunidades puede ser clave para el 茅xito del modelo de predicci贸n. En adelante, la implementaci贸n de estas variables fundamentales en el modelo deber铆a mejorar significativamente su capacidad para prever el cierre exitoso de oportunidades de negocio.

Todo el an谩lisis e informaci贸n que incontraba, lo llevaba en un tabler贸 de miro. Es muy visual y ayuda al equipo a unir y dejar preguntas

[Whiteboard-miro](https://miro.com/app/board/uXjVMflpEIs=/?share_link_id=43714105302)

## Pipelines de preprocesamiento

Dentro de la estructura del proyecto, se han dise帽ado cuatro pipelines que siguen el concepto ETL (Extract, Transform, Load). Cada uno de estos pipelines se encarga de manejar una etapa espec铆fica del proceso, garantizando as铆 la modularidad y la flexibilidad en la ejecuci贸n del flujo de trabajo. Los pipelines se encuentran organizados en la carpeta "src" del proyecto, como se detalla a continuaci贸n:

```

 src
     integrated.py
     join_datasets.py
     preprocessing.py
     train.py
     utils.py
```


1. **preprocessing.py:** Este pipeline se encarga de realizar el preprocesamiento del dataset "offers.csv". Lee el conjunto de datos desde la ruta "datasets/raw/offers.csv" y guarda la versi贸n transformada en "datasets/processed/offers.csv". Aqu铆 se aplican las distintas transformaciones y manipulaciones de variables necesarias para preparar los datos para el entrenamiento del modelo.
2. **integrate_datasets.py:** Este pipeline se enfoca en el preprocesamiento del dataset "lead.csv". Similar al pipeline de "preprocessing.py", toma el dataset desde "datasets/raw/lead.csv" y guarda la versi贸n transformada en "datasets/processed/lead.csv". Se aplican las transformaciones espec铆ficas a este conjunto de datos.
3. **join_datasets.py:** Este pipeline se encarga de la integraci贸n de los dos datasets preprocesados, "offers.csv" y "lead.csv". Lee ambos conjuntos de datos desde sus rutas procesadas respectivas y los une en un 煤nico dataset. El dataset integrado se guarda en "datasets/processed/integrated_dataset.csv".
4. **train_model.py:** Este pipeline representa la etapa de entrenamiento del modelo. Utiliza el dataset integrado generado por el pipeline anterior y realiza el entrenamiento del modelo. Los modelos entrenados se almacenan para su uso posterior en el proceso de predicci贸n.

Esta organizaci贸n modular y la ubicaci贸n de los datasets en carpetas espec铆ficas facilitan la integraci贸n del proyecto con administradores de tareas como Apache Airflow o prefect, permitiendo la automatizaci贸n y programaci贸n del flujo de trabajo. Adem谩s, la estructura del proyecto facilita su mantenimiento y escalabilidad a medida que se incorporan m谩s funciones y se expande el alcance del proyecto.

Cada uno de los pipelines anteriormente mencionados crea autom谩ticamente un informe que se almacena en la carpeta "reports".


```

 reports

     integrated.html

     leads.html

     offer.html

```
